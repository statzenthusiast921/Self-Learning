#Lesson 75: Funamentals of K-Nearest Neighbors

#frequency based machine learning algorithm
#k represents number of neighbors you use for comparison
#NN- nearest neighbor
#good for large amount of data
#measures distances between each data point
#not impracted by variance and covariances
#used for classification usually
#you can use euclidean, manhattan for distance measurement

#instead of assigning clusters, model will assign class (using distance measurements)

#normalize the scale before applying KNN
#recommended number for K should not exceed 19
#recommended to choose k=square root of n where n is # of obs
#KNN can be used to impute missing data

#x: n=100, use K=10
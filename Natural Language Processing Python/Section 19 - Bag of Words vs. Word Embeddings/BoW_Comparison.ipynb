{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoW_Comparison.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBGPbXPIb2Gr"
      },
      "source": [
        "##<font color='#12CBC4'> Comparison Between BoW & Word Embeddings In Detecting Simiarlity & Context<br>Semantic similarity between two words, phrases or even two documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN0upTx_XGyj"
      },
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "#!python3 -m spacy download en_core_web_md\n",
        "#language model\n",
        "import en_core_web_md\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptgQ3qVxawfR"
      },
      "source": [
        "# !pip3 install -U spacy\n",
        "# !python3 -m spacy download en_core_web_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG99BAA0bTzI"
      },
      "source": [
        "##<font color='#12CBC4'>Calculate Similarity Scores With spaCy and BoW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD1SDeqjW_7P"
      },
      "source": [
        "#code to calculate spaCy and BoW similarity scores from two texts\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\") \n",
        "text1 = 'In 1919 there was the Spanish Flu'\n",
        "text2 = 'Covid-19 hit the entire world in 2020 and became a pandemic'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8cgXqA2gcp6"
      },
      "source": [
        "##<font color='#12CBC4'> Spacy Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM0E8zGhgLdJ",
        "outputId": "4070f549-0964-4aa9-c3d4-6793fb5ae50c"
      },
      "source": [
        "#Calculates spaCy similarity between texts 1 and 2\n",
        "doc1 = nlp(text1)\n",
        "doc2 = nlp(text2)\n",
        "print(\"spaCy similarity:\", doc1.similarity(doc2))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spaCy similarity: 0.8024310959887129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPMDYQB6ggTF"
      },
      "source": [
        "##<font color='#12CBC4'>BoW Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI683ZvYgWH5",
        "outputId": "c6aa584b-06c0-4725-ad37-1442359e8a8a"
      },
      "source": [
        "#Calculate cosine similarity using Bag-of-Words \n",
        "documents =[text1, text2]\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
        "doc_term_matrix = sparse_matrix.todense()\n",
        "df = pd.DataFrame(doc_term_matrix, columns=count_vectorizer.get_feature_names(), index=['x', 'y'])\n",
        "print(\"Cosine similarity:\", cosine_similarity(df, df)[0,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7drqqb-kc3j6"
      },
      "source": [
        "<font color='#B53471'>Spacy Notes<br>3 types of word objects in spacy; (1) docs (2) tokens and (3) spans. Docs refer to doc objects made from texts analogous to paragraphs or full documents; while tokens refer to word like chunks which represents the most atomic parts of a doc. spans are continuous list of these tokens; i.e. analogue of a phrase.<br>spaCy md model, which has a relatively small number of vectors (between 10k and 20k), and other tokens mapped to their nearest vector<br>If you try to calculate simiarity using Spacy Small Language Model, you get a warning - bcause no real vector is loaded and the similarity measure is created using ner and pos taggers and similar signs.<br>\n",
        "<br><font color='#FFC312'>The small model basically checks to see the the same words reappear. <font color='#B53471'>The reason behind this is that to optimize the memory usage, spacy doesn't load any real word embedding for the vocabulary it uses when it loads the smaller models. \n",
        "\n",
        "<font color='#B53471'>spaCy uses word vectors for medium (md) and large (lg). Therefore, to use the actual vectors and get better accuracy, use either the medium model i.e. en_core_web_md or the large model i.e. en_core_web_lg. The large model contains a very large vocabulary with unique vectors for more than a million words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDp5DQwqa9Uo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
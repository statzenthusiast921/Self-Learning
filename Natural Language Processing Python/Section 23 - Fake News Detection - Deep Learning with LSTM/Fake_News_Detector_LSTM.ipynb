{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake News Detector_LSTM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62M0HuCsCy2F"
      },
      "source": [
        "# <font color='#badc58'> Fake News Detector with LSTM |<br> </font>  \n",
        "# <font color='#3dc1d3'>  \n",
        "1.  Preprocess data\n",
        "2.  one_hot encoding\n",
        "3.  create LSTM model\n",
        "4.  observe the alteration in shape, flattening and then re-shaping - changes from embedding to flattening - to - dense layer <br>\n",
        "5. Observe the total weight matrix size of the LSTM - mathematical verification\n",
        "\n",
        "## <font color='#f9ca24'> LSTM \n",
        " <font color='00BFEB'>'fit' or train on some training data; joins these two steps and is used for the initial fitting of parameters on the training set ùë•, while also returning the transformed ùë•‚Ä≤. Internally, the transformer object just calls first fit() and then transform() on the same data.<br>In the output, you will see (20000, 5) which means that each of the document has 5 columns where each column corresponds to the probability value of a particular topic. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJuHztF_mRyy"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "from sklearn.metrics import classification_report \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhOZn_gAp9D_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cCmnOf3sg_Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufa40yY4ZtgP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQCBix5NP6JG"
      },
      "source": [
        "### <font color='#badc58'>Let's take a look at the dataset.</font>  <br/> \n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J44IY4ysxFm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuYOLtQhK1t2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enNGZpN3tQlr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP7hSoXitwdp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70rT6LLRNZg3"
      },
      "source": [
        "<font color='#badc58'>drop missing data</font>  <br/> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaLGCTkrt4YK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caj0WLA9uBTr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnibShNT_lY2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCBbMbCcNahk"
      },
      "source": [
        "<font color='#badc58'>Preparing to create the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k6_ggj6xELb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDfv2tzH_9Ce"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK-mHTgeNyzz"
      },
      "source": [
        "<font color='#7ed6df'>Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsdRmr8nKDUV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJi1ppAyHVT7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5PkFDUfxgWv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8JdQpSMKHPO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yraYhSMFP-h3"
      },
      "source": [
        "<font color='#f9ca24'>Keras<font color='#7ed6df'> provide the function <font color='#f9ca24'>one_hot</font> to efficiently encode each word in the titles as an interger.<br>This must be done prior to Word Embedding<br><font color='#7ed6df'>Index of words located in the Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E1urI4y37Oo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjlAGDTla0fJ"
      },
      "source": [
        "<font color='#7ed6df'>Longest sentence<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1slLzoya1O5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4qw6zMMRstV"
      },
      "source": [
        "<font color='#7ed6df'>Making every sentence of the data of Same Length<br> <font color='#f9ca24'>pad_sequences </font>is used to ensure that all sequences in a list have the same length. By default this is done by padding 0 in the beginning of each sequence until each sequence has the same length as the longest sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHPI-B7zRDWk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ByVXLgOmRt3"
      },
      "source": [
        "<font color='#7ed6df'>Arguments: <br>\n",
        "<font color='#f9ca24'>sequences </font>\t\n",
        "List of lists where each element is a sequence<br>\n",
        "<font color='#f9ca24'>maxlen </font>\t\t\n",
        "int, maximum length of all sequences\n",
        "\n",
        "<font color='#f9ca24'>dtype </font>\t<font color='#7ed6df'>\t\n",
        "type of the output sequences\n",
        "\n",
        "<font color='#f9ca24'>padding </font><font color='#7ed6df'>\n",
        "'pre' or 'post', pad either before or after each sequence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5emrujMRvy0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvXIs9mHfVJO"
      },
      "source": [
        "<font color='#7ed6df'>Input shape<br>2D tensor with shape: (batch_size, input_length)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvXhLbg-Rz0r"
      },
      "source": [
        "<font color='#f9ca24'>Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sll9PjfR7Ek"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eqSTAsPb56b"
      },
      "source": [
        "<font color='#7ed6df'>sequence()a plain stack of layers where each layer has exactly one input tensor and one output tensor<br>create a Sequential model incrementally via the add() method<br>the input of the LSTM is always a 3D array\n",
        "(batch_size, time_steps, units)<br>\n",
        "The output of the LSTM could be a 2D array or 3D array depending upon the return_sequences argument.\n",
        "If return_sequence is False, the output is a 2D array. (batch_size, units)\n",
        "If return_sequence is True, the output is a 3D array. (batch_size, time_steps, units)<br> in this case; the return_sequence is false - this is the default, therefore - 2D LSTM output\n",
        "\n",
        "3D tensor with shape: (batch_size, input_length, output_dim).\n",
        "alteration in shape, flattening and then re-shaping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn_nm5VoSArv"
      },
      "source": [
        "<font color='#f9ca24'>Describe model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APhSmNXqJKlE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_n-Yuw7JbSW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa1oIlpIJjMW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lISGeQLlSD_w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHn8tv7Ifgqb"
      },
      "source": [
        "<font color='#7ed6df'>fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5JwUE7vJi0O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSiMBfeMKFta"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqo70bV0Ka5W"
      },
      "source": [
        "<font color='#7ed6df'>Describe performance of classificaiton model <br>tweak to make sure that 'acc' and 'val_acc' and final 'accuracy' are more closer to each other. It is normal for validation accuracy to be lower than accuracy. But ideally, these values should be kept similar range. If validation accuracy is much lower than accuracy, be cautious of over fitting<br>acc' refers to accuracy of what was trained against. <br>'val_acc' refers to validation set. Note that val_acc refers to a set of samples that was not shown to the network during training and hence refers to how much your model works in general for cases outside the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvk7CylVKkGh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDCp5CUcKKdl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xay-VsxfSLCU"
      },
      "source": [
        "<font color='#7ed6df'>Evaluate Performance with Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5_KHq_jSJ_f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQXEbQ4ZSR9B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8w0BzSobXsN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}